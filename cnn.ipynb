{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las imágenes generadas por el código `delphes_gans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h.File(\"new.h5\", 'r')\n",
    "images = np.vstack([f[\"qcd/images\"][:], f[\"wprime/images\"][:]])\n",
    "labels = np.hstack([f[\"qcd/labels\"][:], f[\"wprime/labels\"][:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acomodamos la información y separamos en datos de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alfredo/anaconda2/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "images = np.reshape(images, [-1, 25, 25, 1])\n",
    "labels = to_categorical(labels)\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones ayudan a crear la red más flexible y rápida. Cada una de ellas define una nueva **capa** de la red. Entendemos como capa a cada operación del flujo de datos en la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        shape   = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "        biases  = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "        layer   = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights\n",
    "    \n",
    "def pool_layer(input, name):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        return layer\n",
    "\n",
    "def relu_layer(input, name):    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        layer = tf.nn.relu(input)\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "def fully_connected_layer(input, num_inputs, num_outputs, name):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases  = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        layer   = tf.matmul(input, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 25, 25, 1], name='X')\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 2], name='Y')\n",
    "\n",
    "conv1, weights1 = conv_layer(X, num_input_channels=1, filter_size=5, num_filters=6, name=\"conv1\")\n",
    "pool1 = pool_layer(conv1, \"pool1\")\n",
    "relu1 = relu_layer(pool1, \"relu1\")\n",
    "\n",
    "conv2, weights2 = conv_layer(relu1, num_input_channels=6, filter_size=5, num_filters=16, name=\"conv2\")\n",
    "pool2 = pool_layer(conv2, \"pool2\")\n",
    "relu2 = relu_layer(pool2, \"relu2\")\n",
    "\n",
    "num_features = relu2.get_shape()[1:].num_elements()\n",
    "layer_flat = tf.reshape(relu2, [-1, num_features])\n",
    "\n",
    "layer_fc1 = fully_connected_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "layer_relu3 = relu_layer(layer_fc1, name=\"relu3\")\n",
    "layer_fc2 = fully_connected_layer(layer_relu3, num_inputs=128, num_outputs=2, name=\"fc2\")\n",
    "\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2, labels=Y)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, tf.argmax(Y, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "writer = tf.summary.FileWriter(\"cnn/Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"cnn/Validation_FileWriter/\")\n",
    "\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed\n",
      "\t- Training Accuracy:\t0.47823187708854675\n",
      "\t- Validation Accuracy:\t0.47428572177886963\n",
      "Epoch 10 completed\n",
      "\t- Training Accuracy:\t0.737353503704071\n",
      "\t- Validation Accuracy:\t0.7424761652946472\n",
      "Epoch 20 completed\n",
      "\t- Training Accuracy:\t0.7799371480941772\n",
      "\t- Validation Accuracy:\t0.774476170539856\n",
      "Epoch 30 completed\n",
      "\t- Training Accuracy:\t0.7952748537063599\n",
      "\t- Validation Accuracy:\t0.7908571362495422\n",
      "Epoch 40 completed\n",
      "\t- Training Accuracy:\t0.8023244738578796\n",
      "\t- Validation Accuracy:\t0.7961905002593994\n",
      "Epoch 50 completed\n",
      "\t- Training Accuracy:\t0.8081356287002563\n",
      "\t- Validation Accuracy:\t0.804190456867218\n",
      "Epoch 60 completed\n",
      "\t- Training Accuracy:\t0.8141373991966248\n",
      "\t- Validation Accuracy:\t0.8087618947029114\n",
      "Epoch 70 completed\n",
      "\t- Training Accuracy:\t0.8189006447792053\n",
      "\t- Validation Accuracy:\t0.8140952587127686\n",
      "Epoch 80 completed\n",
      "\t- Training Accuracy:\t0.824616551399231\n",
      "\t- Validation Accuracy:\t0.8175238370895386\n",
      "Epoch 90 completed\n",
      "\t- Training Accuracy:\t0.8302372097969055\n",
      "\t- Validation Accuracy:\t0.8220952153205872\n",
      "Epoch 100 completed\n",
      "\t- Training Accuracy:\t0.8355720639228821\n",
      "\t- Validation Accuracy:\t0.8281905055046082\n",
      "Epoch 110 completed\n",
      "\t- Training Accuracy:\t0.8393827080726624\n",
      "\t- Validation Accuracy:\t0.8327618837356567\n",
      "Epoch 120 completed\n",
      "\t- Training Accuracy:\t0.8457654714584351\n",
      "\t- Validation Accuracy:\t0.8373333215713501\n",
      "Epoch 130 completed\n",
      "\t- Training Accuracy:\t0.8516719341278076\n",
      "\t- Validation Accuracy:\t0.8441904783248901\n",
      "Epoch 140 completed\n",
      "\t- Training Accuracy:\t0.8597694635391235\n",
      "\t- Validation Accuracy:\t0.8506666421890259\n",
      "Epoch 150 completed\n",
      "\t- Training Accuracy:\t0.8658664226531982\n",
      "\t- Validation Accuracy:\t0.8548571467399597\n",
      "Epoch 160 completed\n",
      "\t- Training Accuracy:\t0.8709154725074768\n",
      "\t- Validation Accuracy:\t0.8598095178604126\n",
      "Epoch 170 completed\n",
      "\t- Training Accuracy:\t0.8758692741394043\n",
      "\t- Validation Accuracy:\t0.8670476078987122\n",
      "Epoch 180 completed\n",
      "\t- Training Accuracy:\t0.8823473453521729\n",
      "\t- Validation Accuracy:\t0.8731428384780884\n",
      "Epoch 190 completed\n",
      "\t- Training Accuracy:\t0.8883490562438965\n",
      "\t- Validation Accuracy:\t0.8754285573959351\n",
      "Epoch 200 completed\n",
      "\t- Training Accuracy:\t0.8934933543205261\n",
      "\t- Validation Accuracy:\t0.8796190619468689\n",
      "Epoch 210 completed\n",
      "\t- Training Accuracy:\t0.8990187644958496\n",
      "\t- Validation Accuracy:\t0.8864762187004089\n",
      "Epoch 220 completed\n",
      "\t- Training Accuracy:\t0.9052110314369202\n",
      "\t- Validation Accuracy:\t0.8929523825645447\n",
      "Epoch 230 completed\n",
      "\t- Training Accuracy:\t0.9115937948226929\n",
      "\t- Validation Accuracy:\t0.8986666798591614\n",
      "Epoch 240 completed\n",
      "\t- Training Accuracy:\t0.9171192049980164\n",
      "\t- Validation Accuracy:\t0.9066666960716248\n",
      "Epoch 250 completed\n",
      "\t- Training Accuracy:\t0.9211203455924988\n",
      "\t- Validation Accuracy:\t0.9097142815589905\n",
      "Epoch 260 completed\n",
      "\t- Training Accuracy:\t0.9252167344093323\n",
      "\t- Validation Accuracy:\t0.9146666526794434\n",
      "Epoch 270 completed\n",
      "\t- Training Accuracy:\t0.9289320707321167\n",
      "\t- Validation Accuracy:\t0.91695237159729\n",
      "Epoch 280 completed\n",
      "\t- Training Accuracy:\t0.933123767375946\n",
      "\t- Validation Accuracy:\t0.9215238094329834\n",
      "Epoch 290 completed\n",
      "\t- Training Accuracy:\t0.9360769987106323\n",
      "\t- Validation Accuracy:\t0.9241904616355896\n",
      "Epoch 300 completed\n",
      "\t- Training Accuracy:\t0.9383633136749268\n",
      "\t- Validation Accuracy:\t0.9272381067276001\n",
      "Epoch 310 completed\n",
      "\t- Training Accuracy:\t0.941221296787262\n",
      "\t- Validation Accuracy:\t0.928761899471283\n",
      "Epoch 320 completed\n",
      "\t- Training Accuracy:\t0.9436029195785522\n",
      "\t- Validation Accuracy:\t0.9329524040222168\n",
      "Epoch 330 completed\n",
      "\t- Training Accuracy:\t0.9456034898757935\n",
      "\t- Validation Accuracy:\t0.9348571300506592\n",
      "Epoch 340 completed\n",
      "\t- Training Accuracy:\t0.9471277594566345\n",
      "\t- Validation Accuracy:\t0.9375237822532654\n",
      "Epoch 350 completed\n",
      "\t- Training Accuracy:\t0.9488425254821777\n",
      "\t- Validation Accuracy:\t0.9386666417121887\n",
      "Epoch 360 completed\n",
      "\t- Training Accuracy:\t0.950271487236023\n",
      "\t- Validation Accuracy:\t0.9386666417121887\n",
      "Epoch 370 completed\n",
      "\t- Training Accuracy:\t0.9521768093109131\n",
      "\t- Validation Accuracy:\t0.9398095011711121\n",
      "Epoch 380 completed\n",
      "\t- Training Accuracy:\t0.9529389142990112\n",
      "\t- Validation Accuracy:\t0.9401904940605164\n",
      "Epoch 390 completed\n",
      "\t- Training Accuracy:\t0.9538915753364563\n",
      "\t- Validation Accuracy:\t0.9398095011711121\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 400\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        feed_dict_train = {X: x_train, Y: y_train}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        if epoch%10==0:\n",
    "            train_summ, train_acc = sess.run([merged_summary, accuracy], feed_dict=feed_dict_train)\n",
    "            val_summ, val_acc = sess.run([merged_summary, accuracy], feed_dict={X: x_test, Y: y_test})\n",
    "            writer.add_summary(train_summ, epoch)\n",
    "            writer1.add_summary(val_summ, epoch)\n",
    "        \n",
    "            saver = tf.train.Saver(max_to_keep=15)\n",
    "            saver.save(sess,\"cnn/epoch{:04}.ckpt\".format((epoch)))\n",
    "        \n",
    "            print(f\"Epoch {str(epoch)} completed\")\n",
    "            print (\"\\t- Training Accuracy:\\t{}\".format(train_acc))\n",
    "            print (\"\\t- Validation Accuracy:\\t{}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
